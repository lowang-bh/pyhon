{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 航班准点分析\n",
    "根据包含州(state)和城市(city)的航班数据进行spark数据分析（需要关联几个数据源）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame与表的构建\n",
    "基于pyspark最快捷的数据分析方式是使用DataFrame完成SQL的查询，我们来尝试一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件路径\n",
    "flightPerfFilePath = \"/data/departuredelays.csv\"\n",
    "airportsFilePath = \"/data/airport-codes-na.txt\"\n",
    "\n",
    "# 读取机场数据并注册airports表中\n",
    "airports = spark.read.csv(airportsFilePath, header='true', inferSchema='true', sep='\\t')\n",
    "airports.createOrReplaceTempView(\"airports\")\n",
    "\n",
    "# 读取启程信息数据并注册FlightPerformance表\n",
    "flightPerf = spark.read.csv(flightPerfFilePath, header='true')\n",
    "flightPerf.createOrReplaceTempView(\"FlightPerformance\")\n",
    "\n",
    "# Cache一下以便后续计算\n",
    "flightPerf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出表信息（print schema）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取表的统计信息（describe等）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Sum of Flight Delays by City and Origin Code (for Washington State)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Sum of Flight Delays by State (for the US)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大家可以查阅的资料包括:\n",
    "* [Spark SQL, DataFrames and Datasets Guide](http://spark.apache.org/docs/latest/sql-programming-guide.html#sql)\n",
    "* [PySpark SQL Module: DataFrame](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame)\n",
    "* [PySpark SQL Functions Module](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "name": "Ch4 - DataFrames",
  "notebookId": 4341522646494009
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
